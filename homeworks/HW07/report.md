# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.


## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

 * S07-hw-dataset-01.csv

 * S07-hw-dataset-02.csv

 * S07-hw-dataset-03.csv

### 1.1 Dataset A
 - Файл: S07-hw-dataset-01.csv
 - Размер: (12000 строк, 9 столбцов)
 - Признаки: Все числовые (f01–f08 + sample_id)
 - Пропуски: Нет пропусков
 - "Подлости" датасета:
* Разные шкалы значений (признаки имеют разный диапазон)
* Возможные выбросы (например, f07 от -215 до 213)
* Высокая размерность (8 признаков)


### 1.2 Dataset B

 - Файл: S07-hw-dataset-02.csv
 - Размер: (8000 строк, 4 столбца)
 - Признаки: Все числовые (x1, x2, z_noise + sample_id)
- Пропуски: Нет пропусков
- "Подлости" датасета:
 * Наличие шумового признака z_noise
 * Относительно низкая размерность


### 1.3 Dataset C

 - Файл: S07-hw-dataset-03.csv
 - Размер: (15000 строк, 5 столбцов)
 - Признаки: Все числовые (x1, x2, f_corr, f_noise + sample_id)
 - Пропуски: Нет пропусков
 - "Подлости" датасета:
 * Наличие коррелированного признака f_corr
 * Наличие шумового признака f_noise
 * Разные диапазоны значений


## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

Препроцессинг:
 - Удаление идентификатора (sample_id)
 - Стандартизация всех признаков через StandardScaler
  - Использование Pipeline для последовательной обработки

Поиск гиперпараметров:

 - KMeans: k_range = range(2, 21), фиксированные random_state=42, n_init=10, init='k-means++'
 - AgglomerativeClustering: k_range = range(2, 11), linkage = ['ward', 'complete', 'average']
 - Руководствовались выбором по максимальному silhouette score

Метрики:
 - silhouette_score (чем выше, тем лучше)
 - davies_bouldin_score (чем ниже, тем лучше)
 - calinski_harabasz_score (чем выше, тем лучше)

Визуализация:
 - PCA(2D) для всех датасетов
 - t-SNE для датасетов с ≤5000 образцов (perplexity=min(30, n-1))


## 3. Models

Перечислите, какие модели сравнивали на каждом датасете, и какие параметры подбирали.

Для каждого датасета применялись:

KMeans:

 * Поиск оптимального числа кластеров в диапазоне 2-20
 * Фиксированные параметры: random_state=42, n_init=10, init='k-means++'

AgglomerativeClustering:

 * Поиск оптимального числа кластеров в диапазоне 2-10
 * Тестирование разных типов связи: ward, complete, average


## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

Лучший метод: AgglomerativeClustering
Параметры: {'n_clusters': 2, 'linkage': 'ward'}

Метрики качества:

KMeans:
  * silhouette_score: 0.5216
  * davies_bouldin_score: 0.6853
  * calinski_harabasz_score: 11786.9546

AgglomerativeClustering:
  * silhouette_score: 0.5216
  * davies_bouldin_score: 0.6853
  * calinski_harabasz_score: 11786.9546

Коротко: решение показало наилучший баланс метрик

### 4.2 Dataset B

Лучший метод: AgglomerativeClustering
Параметры: {'n_clusters': 2, 'linkage': 'average'}

Метрики качества:

KMeans:
  * silhouette_score: 0.3069
  * davies_bouldin_score: 1.3235
  * calinski_harabasz_score: 3573.3933

AgglomerativeClustering:
  * silhouette_score: 0.4198
  * davies_bouldin_score: 0.8791
  * calinski_harabasz_score: 395.4826

Коротко: Для датасета с низкой размерностью и шумовым признаком иерархическая кластеризация показала лучшую устойчивость к шуму.

### 4.3 Dataset C

Лучший метод: AgglomerativeClustering
Параметры: {'n_clusters': 2, 'linkage': 'average'}

Метрики качества:

KMeans:
  * silhouette_score: 0.3155
  * davies_bouldin_score: 1.1577
  * calinski_harabasz_score: 6957.1626

AgglomerativeClustering:
  * silhouette_score: 0.4253
  * davies_bouldin_score: 0.8138
  * calinski_harabasz_score: 8.9431

Коротко: Несмотря на наличие шумового и коррелированного признаков, AgglomerativeClustering показал стабильные результаты после стандартизации.


## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

KMeans "ломается" при наличии шума и выбросов, а также когда кластеры имеют разную плотность или не сферическую форму

AgglomerativeClustering выигрывает когда данные имеют иерархическую структуру или когда заранее неизвестно число кластеров

Сильнее всего влияло:
 * Масштабирование признаков (без StandardScaler метрики были значительно хуже)
 * Выбросы (особенно в ds1) снижали качество кластеризации
 * Выбор правильного числа кластеров был критически важен

### 5.2 Устойчивость (обязательно для одного датасета)

Проверка устойчивости: 5 запусков KMeans с разными random_state (42, 123, 789, 2023, 404) на ds1

Результаты:
 - Silhouette score не варьировался
 - ARI не менялся

Вывод: KMeans показал высокую устойчивость на ds1.

### 5.3 Интерпретация кластеров

Метод интерпретации: Анализ средних значений признаков для каждого кластера и визуализация через PCA

Выводы:

 - Кластеры в ds1 соответствуют разным комбинациям значений признаков f02 и f04
 - В ds2 кластеры соответствуют разным уровням шума (z_noise)
 - В ds3 выделились кластеры с разной силой корреляции между x1 и f_corr
 - Шумовые признаки (z_noise, f_noise) не были определяющими для кластеризации

## 6. Conclusion

 * Масштабирование критически важно для методов, основанных на расстояниях (KMeans, AgglomerativeClustering)
 * Выбор метрики зависит от задачи: silhouette хорош для оценки разделения, Davies-Bouldin для компактности
 * KMeans эффективен для сферических кластеров сравнимого размера, но чувствителен к выбросам
 * AgglomerativeClustering лучше справляется с кластерами сложной формы и позволяет анализировать иерархию
 * Визуализация (PCA/t-SNE) необходима для понимания структуры данных и проверки результатов
 * Устойчивость кластеризации зависит от четкости разделения кластеров
 * Интерпретация кластеров через профили признаков помогает понять природу выделенных групп
 * Комбинированный подход (использование нескольких методов и метрик) дает более надежные результаты