# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.


## 1. Dataset

Выбранный датасет: S06-hw-dataset-01.csv

Размер: 12000 строк, 30 столбцов (28 признаков + id + target)

Целевая переменная: target (бинарная классификация: 0 и 1)

Класс 0: 8119 записей (67.66%)

Класс 1: 3881 записей (32.34%)

Признаки:

Числовые: 24 признака num01-num24 (нормализованные числовые значения)

Категориальные: 3 признака cat_contract, cat_region, cat_payment (представлены как числовые коды)

Дополнительный числовой: tenure_months (продолжительность в месяцах)


## 2. Protocol

Разбиение на train/test: 80%/20%, random_state=42, stratify=y (сохранение пропорций классов)

Подбор гиперпараметров: GridSearchCV с 3 фолдами (StratifiedKFold), оптимизация по F1-score

Метрики оценки:

accuracy: общая точность предсказаний

f1: баланс между precision и recall (важно при дисбалансе классов)

ROC-AUC: способность модели различать классы (особенно важна для бинарной классификации)


## 3. Models

Обязательные модели:

DummyClassifier (strategy='most_frequent'): baseline, всегда предсказывает самый частый класс

LogisticRegression (Pipeline со StandardScaler): линейная модель для бинарной классификации

DecisionTreeClassifier (контроль сложности через max_depth и min_samples_leaf)

Подбираемые параметры: max_depth [3, 5, 7], min_samples_leaf [1, 3, 5], criterion ['gini']

RandomForestClassifier (лесная модель с регуляризацией)

Подбираемые параметры: n_estimators [100], max_depth [5, 10, None], min_samples_leaf [1, 3], max_features ['sqrt']

GradientBoostingClassifier (boosting-модель)

Подбираемые параметры: n_estimators [100], learning_rate [0.05, 0.1], max_depth [3, 5], min_samples_split [5]

Опциональная модель:

StackingClassifier: DecisionTree + RandomForest + LogisticRegression (метамодель), обучение с использованием CV-логики


## 4. Results

Финальные метрики на test-выборке:

                Model  Accuracy  Precision  Recall      F1  ROC-AUC
0            Stacking    0.9312     0.9123  0.8711  0.8912   0.9668
1        RandomForest    0.9258     0.9284  0.8351  0.8792   0.9666
2    GradientBoosting    0.9204     0.9173  0.8286  0.8707   0.9663
3        DecisionTree    0.8592     0.8390  0.6985  0.7623   0.8894
4  LogisticRegression    0.8275     0.7828  0.6456  0.7076   0.8747
5               Dummy    0.6767     0.0000  0.0000  0.0000      NaN

Победитель: Stacking

Объяснение: Stacking показал наивысший ROC-AUC (0.9668) и F1-score (0.8912), что указывает на лучшую способность различать классы и лучший баланс между точностью и полнотой по сравнению с другими моделями.


## 5. Analysis

**АНАЛИЗ УСТОЙЧИВОСТИ МОДЕЛЕЙ**

Результаты 5 прогонов с разными random_state:
============================================================

random_state = 42:
  RandomForest: F1 = 0.8792, ROC-AUC = 0.9666
  LogisticRegression: F1 = 0.7076, ROC-AUC = 0.8747

random_state = 43:
  RandomForest: F1 = 0.8954, ROC-AUC = 0.9679
  LogisticRegression: F1 = 0.7140, ROC-AUC = 0.8776

random_state = 44:
  RandomForest: F1 = 0.8800, ROC-AUC = 0.9643
  LogisticRegression: F1 = 0.7109, ROC-AUC = 0.8789

random_state = 45:
  RandomForest: F1 = 0.8895, ROC-AUC = 0.9693
  LogisticRegression: F1 = 0.7302, ROC-AUC = 0.8873

random_state = 46:
  RandomForest: F1 = 0.8824, ROC-AUC = 0.9692
  LogisticRegression: F1 = 0.6988, ROC-AUC = 0.8753

============================================================
СТАТИСТИКА ПО 5 ПРОГОНАМ:
============================================================

RandomForest:
  F1-score: среднее = 0.8853, ст. отклонение = 0.0062
  ROC-AUC: среднее = 0.9674, ст. отклонение = 0.0019

LogisticRegression:
  F1-score: среднее = 0.7123, ст. отклонение = 0.0103
  ROC-AUC: среднее = 0.8788, ст. отклонение = 0.0045

============================================================
ВЫВОД ПО УСТОЙЧИВОСТИ:
============================================================

RandomForest показывает более стабильные результаты (меньшие стандартные отклонения)
при изменении random_state, что ожидаемо для ансамблевых методов.
LogisticRegression несколько более чувствительна к инициализации весов и разбиению данных,
но все равно демонстрирует приемлемую устойчивость.

**CONFUSION MATRIX**

Confusion Matrix:
[1574  50]  # True Negative: 1574, False Positive: 50
[128 648]  # False Negative: 128, True Positive: 648

Интерпретация:
----------------------------------------
Всего объектов: 2400
Правильно предсказано: 2222 (92.6%)
Ошибочно предсказано: 178 (7.4%)

Ошибки I рода (False Positive): 50 (3.1% от класса 0)
Ошибки II рода (False Negative): 128 (16.5% от класса 1)

1. **Общая эффективность**: Модель демонстрирует высокую точность (92.6% правильных предсказаний)
   на тестовой выборке из 2400 объектов.

2. **Баланс ошибок**: Наблюдается дисбаланс в типах ошибок:
   - Ошибки I рода (False Positive): 50 (3.1% от класса 0) - редкие случаи, когда модель
     ошибочно определяет объект класса 0 как класс 1
   - Ошибки II рода (False Negative): 128 (16.5% от класса 1) - более частые случаи,
     когда модель пропускает объекты класса 1

3. **Интерпретация для практического применения**:
   - Если класс 1 представляет важное событие (например, мошенничество, заболевание),
     то относительно высокий процент False Negative (16.5%) может быть проблематичным
   - Низкий процент False Positive (3.1%) означает, что когда модель предсказывает
     класс 1, она обычно права

4. **Следующие шаги для улучшения**:
   - Смещение в сторону большего числа False Negative может указывать на то,
     что модель слишком консервативна при обнаружении класса 1
   - Для улучшения recall (уменьшения False Negative) можно рассмотреть:
     * Настройку порога классификации
     * Использование весов классов
     * Применение техник работы с дисбалансом данных

**PERMUTATION IMPORTANCE (ТОП-15 ПРИЗНАКОВ)**

Топ-15 признаков по permutation importance:
------------------------------------------------------------
№   Признак              Важность (средняя)   Станд. отклонение   
------------------------------------------------------------
1   num19                0.059965             0.001474            
2   num18                0.057000             0.004325            
3   num07                0.024241             0.001268            
4   num04                0.016113             0.001306            
5   num20                0.013931             0.001844            
6   num01                0.011241             0.001214            
7   num24                0.008107             0.000880            
8   num22                0.007082             0.001136            
9   num08                0.007006             0.000934            
10  num14                0.006310             0.000666            
11  num16                0.006262             0.000819            
12  num21                0.006244             0.001075            
13  num17                0.005283             0.000512            
14  num06                0.005117             0.000942            
15  num13                0.004507             0.001300

1. **Явные лидеры**: Признаки `num19` и `num18` значительно превосходят остальные по важности
   (0.059965 и 0.057000 соответственно), что указывает на их ключевую роль в предсказаниях модели.

2. **Второй эшелон**: Признаки `num07`, `num04` и `num20` имеют умеренную важность
   (0.024241, 0.016113, 0.013931), существенно уступая лидерам, но всё же заметно влияя на модель.

3. **Равномерное распределение**: Остальные 10 признаков имеют схожую низкую важность
   (0.004507-0.011241), что указывает на их второстепенную роль в модели.

4. **Стабильность оценок**: Низкие стандартные отклонения (0.000512-0.004325) показывают,
   что оценка важности признаков стабильна при повторных перестановках.

5. **Доменная интерпретация**:
   - Тот факт, что именно `num19` и `num18` оказались наиболее важными, может указывать
     на то, что эти признаки содержат наиболее релевантную информацию для задачи
   - Отсутствие явной важности у первых признаков (num01-num03) и последних (num23-num24)
     может указывать на то, что информация распределена неравномерно по признакам
   - Категориальные признаки (cat_*) не вошли в топ-15, что говорит об их меньшей
     значимости для данной задачи классификации

6. **Практические рекомендации**:
   - Для упрощения модели можно рассмотреть удаление признаков с наименьшей важностью
     (например, ниже 0.005)
   - При сборе данных можно уделить больше внимания измерению характеристик,
     аналогичных `num19` и `num18`, так как они наиболее информативны
   - Возможна попытка создания новых признаков на основе `num19` и `num18`
     для улучшения качества модели


## 6. Conclusion

1. Stacking доказал свою эффективность как ансамблевый метод: Стекинг-модель показала наилучшие результаты по всем метрикам (F1=0.8912, ROC-AUC=0.9668, Accuracy=0.9312), превзойдя все одиночные модели. Это демонстрирует силу комбинации разнородных алгоритмов (DecisionTree + RandomForest + LogisticRegression) через обучение метамодели.

2. Ансамблевые методы значительно превосходят одиночные модели:

 * RandomForest (F1=0.8792, CV-F1=0.8834) показал отличные результаты благодаря усреднению множества деревьев

 * GradientBoosting (F1=0.8707, CV-F1=0.8811) также продемонстрировал высокое качество благодаря последовательной коррекции ошибок

 * Обе ансамблевые модели значительно превзошли DecisionTree (F1=0.7623, CV-F1=0.7841)

3. Контроль сложности критически важен для деревьев: DecisionTree с подобранными параметрами (max_depth=7, min_samples_leaf=5) показал приемлемые результаты, но все же уступает ансамблевым методам. Без контроля глубины и минимального числа образцов в листьях дерево склонно к переобучению.

4. Честный ML-протокол подтвердил свою важность:

 * Разделение данных (80/20) с сохранением пропорций классов через stratify

 * Подбор гиперпараметров только на train через GridSearchCV с кросс-валидацией (3 фолда)

 * Однократная оценка на тесте предотвратила data leakage

 * Разница между CV- и test-метриками минимальна, что указывает на корректность протокола

5. Качественные метрики важнее единой метрики:

 * Stacking показал лучший баланс между precision (0.9123) и recall (0.8711)

 * RandomForest имел выше precision (0.9284), но ниже recall (0.8351)

 * ROC-AUC (0.9668 для Stacking) подтвердил отличную способность моделей различать классы

6. Интерпретируемость моделей остается вызовом:

 * Permutation importance выявил ключевые признаки (num19, num18, num07)

 * Однако сложность интерпретации Stacking выше, чем у отдельных моделей

 * Для production-систем нужно балансировать между качеством и интерпретируемостью